 what's going on youtube this is ipsec i'm doing sync from hack to box which is probably one of my favorite boxes in a long time because it taught me a lot of things that was on my to-do list but i just never found the time to learn about them the first off is doing an http smuggling attack i knew kind of about it but never understood the implications in this would use the http smuggling in order to steal another person's cookie kind of like a cross-site scripting attack but with no javascript whatsoever just a fun attack amongst the protocol itself then once we get a shell on the box we enumerate a bunch of aws secrets things querying the secret manager to pull some passwords and then creating the kms to decrypt the file and then once we get root i'm going to talk about what me and oxdf did to make this box stable i learned a lot about like kernel modules which i don't show in this video that's in the uhc september qualifiers in this video we talked about using iptables rules to create a ipmodulo router which i think is pretty cool but with that being said let's jump in as always i'm gonna start with the nmap so dash sc for default scripts sv enumerate versions oh a output all formats put in the map directory and call it sync and then the ip address which is 10 10 10 2 2 5. this can take some time to run so i've already ran it looking at the results we have a lot of information here so let's just start off from the top our first thing is ssh on port 22 and its banner tells us it's an ubuntu server if we look at the specific version for ubuntu 0.1 this is unique to ubuntu bionic which is i believe 18. so if you just google this string or go to launchpad and search it you'll find out that this is ubuntu 18. not much you can do with that information other than if you tried to mimic the server for any reason like doing a binary exploitation down the line that's the distro you'd want to pull the next thing we have is port 3000 nmap doesn't exactly know what 3000 is by default it thinks it's ppp which i think is point-to-point protocol but it runs this fingerprint settings script which essentially just connects the socket and dumps a bunch of information so it's sending a 400 bad request so we know this is an http server and the reason why it sends it is because it kind of just connects the socket and sends it gibberish which isn't a valid um http request we can try to mimic it like 10 10 10 2 5 port 3000 if i just say like please subscribe and hit enter we get that 400 request if we sent a normal http request like get slash http is it slash 1.1 like that uh required host header but it's giving us more information so we could follow on and say get slash http 1.1 host ipsec and we get a page so because nmap isn't sending a valid http request that's why it sends this 400. if it does send a get request we're getting this 200 and it looks like a page back if we look at the title it's get t get with a cup of tea we got a csrf token um a cookie that says i like get t so this is definitely um an application called get t going to the next port we have 5000 this is http and nmap is telling us this is g unicorn version 20.0.0 just like before with ubuntu i always like looking at exactly what this version tag is so i'm going to go over to google and just search g unicorn change log and we gotta put a space there uh let's see go to google go to the change log and we can see 20.1.0 release 2021 february 12th but we're on 20.0.0 so i'm going to go to the changelog 2020 and we see there isn't really any versions here it just says one unreleased so let's go change log 2019 and we can see 2004 was released 2019 november 26th uh november 23rd is twenty zero one it was like man it was active right here that's like three minor versions in a week uh 29 uh version 19 was released november 23rd we can keep going down we see 20.0 comes out october 30th so october 30th is our version then the next release we can look at the results and they fix chunk encoding support to prevent any request muggling so this piece could be key later on but i'm just going to continue with my enumeration trying to remember about request muggling if i run into issues so let's go to get t which is 10 10 10 2 2 5 and we have this page um i'm going to do control u to see if it has any like version indicator of this and i can't see anything we have go 1.14.12 so we can also go to google and search for this and see if we find when this is uh june 10th where was it uh google said june 10th but this says september 9th 2021 which doesn't look right because that is like a day ago right like this box is retired it should be much older let's see let's go to this page we get this okay this looks better november 12 2020 is probably around the time this go version released so you should be taking like notes of just all the versions and the dates to build kind of a story around the box that g unicorn being two years old is the thing that sticks out the most so far uh we can try to enumerate get teas version so generally what i do is go get t uh github see if it's open source looks like it is and it is a goling application hinted by the li uh repository beginning with go dash and then looking at these files uh is there a go yeah golang.yaml so uh i don't know exactly how to enumerate girling apps or how like they generally work under the hood i'm just going to check if this changelog.md exists because it is 13 days ago and looking at it looks like we have a bunch of versions so i'm going to try going to slash changelog.md we get a 404 they have this web source directory so this is probably where i'm going to start web source js so let's try this slash js we don't have anything but if i do f12 refresh the page let's see we have some javascript files so jquery and jquery is within this js directory so we can do js jquery uh do i have a space or something let's paste in the folder name and we get this page if we just do jslash we get a 404 if we put a file afterwards that doesn't exist we get this uh still 404 page but less data so we have a way to enumerate if folders exist on the server by just making it access a um file and oh man we got a version right here get t version awesome we don't have to go into any more because we know it's 1.12.6 that is good so let's go over to here uh get t and i have not prepped any of this like enumeration stuff so this is all going kind of live so i was actually surprised to see it there uh go to changelog we can look at 1.12.6 man did not even on this 1.14 1.12.3 5. there's a lot of data here so 1.13 is 20 20. so 1.13.1 so i can search that 1.12. huh 6 doesn't exist on this change log but it's here weird but we know it's probably sometime after um october and 2020. so still the oldest thing right now is aj proxy and keep in mind that these boxes are generally like six months old by the time they retire so get t probably upon release was near the latest version uh the other thing i do if that did not work i would go and download this jquery file so let's go jquery.js we can go here make the attempt so we don't clog this up wget jquery md5 summit and we could google the md5 sum probably get nothing because it just doesn't work that way so nothing here but if we go to virustotal this is one of my favorite ways to identify like when a file is released just go over to the search tab put that md5 sum in virustotal and we can see it was probably last seen seven months ago but if we go over to this details tab we can see the first mission october 24th which kind of relates to the um get t version now um because we know get t was 2020 october 10th or yeah october sometime after that and was first submitted here so it's probably that version like around that date so i'm saying a lot of words let me go back enumerating the date of get t via jquery is probably correct because based upon the change log we know it was released in the same month that virusturtle's first seeing this jquery file so that's actually pretty cool um didn't know that when i was first like walking through this box but that's enough looking at get t i'm gonna look at the next thing which is port 5000 and this is where that outdated version of um g not g yeah g unicorn was running so if i try to sign in let's try admin password we don't get anything we just get invalid credentials but we can sign up so i'm going to try signing up the username i'm going to do is just ipsec pass or email is going to be root ipsec.rocks and i'll try a password of password i'm going to just start turning burp suite on so i'm logging the request i can go back and look at them burp suite is like not intercepting but this way when i click sign up and if i get um stuck i can just go to http history and kind of look at the request and then we could try things like changing ipsec to put um like cross-site scripting in here so like if i did uh bold ipsec slash bold we could try seeing if this works um there is cross site request forgery so we probably will just get a csrf error if we do that but i don't see where it's saying my name here too much we got email up here but things i would try if i run into a big wall not focusing on too much we can leave comments so i'm going to do the same thing see if it processes html if it does process the html and this comment is bold i would try putting a cross-site yeah cross-site scripting thing in to see if anyone's checking this page and potentially steal their cookies don't have anything there if we go to this notes page uh we can enter a note same thing uh bold test dot test slash b just one of the payloads i generally do um you can click view and we still see those tags again i'm looking to see if test was bolded other thing you could do is like um seven times seven and these curly braces to see if it's server side uh our ssti server side template injection click this we don't see like seven sevens or 49 so not ssdi we can delete our note so if i click delete we have this the other thing we could try is um a like eidor thing trying to access a note we don't have access to so we could try fuzzing note one uh was it a post what was that three five nine one three is that what i tried to get here let's buy like the deleted note so we can try like notes 2 just get redirected here if i copy this let's try something real quick let's do note 9001 because i don't think that node exists and we still get and we get an internal server error so we kind of have an eye door vulnerability i think uh we can't actually get the information but we can confirm a note exists potentially because if we try a low number note which we assume is going sequential it just sends us a redirect so chances are the application is saying if this note exists check if i have permission if i don't have permission redirect me but if the note doesn't exist then it's hitting some type of error in the web application so that's just interesting to note we can validate that notes exist going over to the contact contact does nothing so looking back at this tab we can see this via tag and says via aj proxy and ha proxy is just something that sits in front of g unicorn it stands for like high availability proxy so this ip address is checking multiple web servers if one web server goes down it would send it to the next one but it's interesting why both of these things exist on the server especially a g unicorn version that we previously discovered is two years old so i'm gonna do is just google for like g unicorn ha proxy and see what we get uh to do that i want to turn burp suite off so g unicorn h a proxy go to google and let's see add exploit and the tag it's funny that google is like oh you want to add exploit into this and looks like we have a defcon ctf based upon this specific version so we could read this post it's talking about doing some type of chunking adding a vertical tag on this transfer encoding chunked header and also sending a content length header um this isn't the post i had came this isn't the post i used to understand the vulnerability it is over here so if you're confused i would recommend reading both of these because all my understanding of http smuggling is based off this machine i had not done it before so i may be wrong when i'm trying to explain things but essentially this works because let's go over to burp suite real quick let's turn it on send this request it works because um when we interact with this service it is sending the request to h a proxy which then sends it over to g unicorn because the tcp handshake for each pack it's actually quite a bit of overhead there's this thing called chunking which allows you to do multiple http requests in one single packet now they use the vertical tab when they do the chunking request because h a proxy is going to ignore it and then when it makes its way over to g unicorn g unicorn doesn't ignore the vertical tab and treats it as a chunk thing letting you do to hijack the request so i'm going to delete some of this header so we don't really go um off this or by off this i mean like way too far down see let's move this connection closed dnt i forget what that is we don't need all this except i think this is all we need yep the http request works so what i'm going to do is add the transfer dash encoding and we're going to say chunked and we also have to add um the vertical tag or vertical tab tab and it's a bit of a pain to add it into burp suite um the best way i've done it is if we just do man ascii we can see the vertical tab is hex 0b so we can do print f and then backslash x 0 b and it's going to show nothing but if i xxd yet um it comes out to 0b if we do like 4 1 it comes out to capital a because 41 is hex for capital a so we're going to do 0b then base64 encode it and we get this cw equals equals i'm going to copy that i'm going to put it here and then highlight convert selection base64 base64 d code and it magically disappears but if i highlight the section i can see selected text has this box because it can't display that character and says it is chunked the other thing we need which i'm surprised i don't see it maybe i accidentally deleted it is the content length tag i'm going to remove this send let's see okay there we go rip suite will automatically add this content length and it's a bit annoying um sometimes at least when doing http smuggling because it's going to auto populate the content length with whatever is in the http body if you want to remove that feature you can just go to this repeater and update length and take that off so it will no longer automatically populate that but we can leave that enabled for now and the reason why we need this is because we added this vertical tab ha proxy is going to ignore this encoding and it's going to obey the content length so we want to add a second request and before we do that we add this zero and that's because of how chunking works if you look at like the rfc for this it's kind of like a serialized format so the whole idea of this is to be able to send multiple data or multiple things in one packet on different tcp connections so we could say like uh four and then message equals and then or we did the four because message equals is four characters and then the next thing we could say three and then or we can say four again then test so we send the length we send how much we want then we send the length how much we want if it was only one character we would do one a and then when it sees zero this is when it terminates that http request so because we don't actually need anything in this body i can just leave it at zero and then we can go start crafting the next one so i'm gonna do a um let's log in again real quick before we go on so turn off i can do root ipsec login with password what root ipsec.rocks password login probably had a typo we can either do this with a comment or we can do it on a note since i want to kind of keep this private i'm probably going to favor towards doing it on a note because anyone can see the comments page so if i was trying to do an attack with smuggling i wouldn't want anyone to be able to see it i only want that information so i'm going to do it on this note page so let's intercept this request so we can see what the packet looks like intercept is on go to burp suite save it and it's doing a post to slash notes using my cookie uh we probably don't need the get t stuff we just need session so let's go and send this over to repeater i'm going to send this to be model i guess this will be smuggle so on model we need to send post we need the host header set we probably need our cookies uh whoops repeater smuggle cookies and then we need content length and then we also need the body which is note is equal to and we leave this blank so the idea here is we are going to um start a get request and h a proxy is going to send this whole thing and then if someone else makes a request they're just going to append data to a note and then when it sends it to g unicorn g unicorn's going to go oh this is a chunked request here is the very first get request and here's the second one and this is the data of the next person to hit the page and for this we'll have to know kind of like the content length because this is where like burp suite probably limits a lot of people's understanding because it automatically always populates this but let's turn this off refresh the page and just go like that i'm going to go back to prep suite i'm going to say please subscribe right and we send this go to repeater we can see the content length is 21 because this if we do echo dash n wc-c is 21 characters so if i just send this request it'll say we are redirected i can go off of burp suite and when i view this note we see it says please subscribe now if this content length was different um subscribe looks like it is for except for let's just remove 10 characters from this so content length is now 11. again i'm not taking the note or changing the note in any way and we go back to notes go view oh that oh crap so remember i changed it and we're back here uh we have to go to repeater tab take that stupid update content length automatically off go here and view the latest note it only says please now because when g unicorn process it said oh the content length is 11. okay that's 11 characters i'm going to stop processing after this and drop it so that's why for this content length we actually kind of want to get an idea how big the header is so i'm just going to copy this we can v test.text paste this wc-c on test.txt 155 but if i grab like a normal request let's see what this is real quick vtest.text wc-c this is 580. we can try 580 to see what happens so let's go back to smuggle 580. and then this content length is going to be the length of this and we can just leave it at auto generate because that's fine if i grabbed this did v test.text deleted this replace it here wc-c 173 because i have a line break at the end of this probably that is counting but that's where the content length is there so let's go and see if we trigger this ever so i'm going to delete all these comments or links and we're going to send the request a few times notice this time it is hanging i'm not sure why it's hanging for so long this time probably because um this content length is too big and the person that we smuggled against adding it didn't send enough data for this content length to finish so it's kind of just hung that request if i refresh this page we don't have anything so what i want to do let's drink this content request let's just say 280. send this a few times again this time it looks like it redirected and if i view this note we can see is this myself this one maybe my own cookie whoops did not mean to do that we can just see what this ends in ey that looks same this looks like potentially my cookie so because i refreshed like too quickly i hdb smuggled on myself and that's not the goal so let's go back to notes to see if we have anything else we have a few more keys for me hitting that this is note slash delete i've never query delete and we have a different cookie so this one looks good can do f12 go into storage change out the session for the new session and when i refresh i am now admin at sync.hdb and we have access to ids one two and three so before we go digging into this i wanna make this a little bit more reliable so the reason why we had to keep sending this request is because h.a proxy was deciding oh um i have enough data i'm just going to send it over to g unicorn now and if someone didn't come in right after us then it just sends our request if someone comes in right after us it's going to send our request and theirs and we can kind of always win this race condition by just keeping the socket open longer because burp suite does a burp seat repeater doesn't really support the keep alive connection by doing chunking whenever i send this it immediately closes the socket i don't know of a way to keep the socket open but if the socket stayed open longer then it would take longer for h.a proxy to send it the data over to g unicorn and because it takes longer to send the data there's a higher chance that someone comes in right after us so what i'm going to do is let's just copy this entire thing to base64 so let's do let's see convert selection base64 encode we can copy this maker smuggle and v we'll just call this payload.b64 paste this and then i guess we can um go into python real quick so v exploit dot pi and the tricky thing about this exploit we're actually not going to use the python request module even though um we are sending an http request and that's the same reason as burp suite it will just close the socket for us instead i just want to jam data on a network pipe and keep it open and i would use um netcat actually and maybe i'll use netcat if i x-clip this the reason why i wasn't using netcat is because of the um let's do cat payload base64-d to payload but when i copy and paste this i don't know if copy and paste handles this vertical tab well i could probably just x-clip it actually selection dash clipboard let's see x-clip see selection how do we x-clip i slip dash is help x-clip h let's see oh dash selection dash selection clipboard i'm also going to do primary make sure it's on my clipboard that looks weird but let's try it see if it works netcat101010225 port 5000 and i actually probably want to log out because we no longer see our notes there we go so see what happens if i just jam data like this and then control c do we get someone else yeah it doesn't work that well um i'm guessing just how we're sending the data so let's go back to exploit.pi and we want to import socket import time because we need to add a sleep and i think that's all we need so with socket.socket we want to do tcp so this is essentially like mimicking netcat the first thing we're going to do is connect and we send it a tuple so we do that two parentheses 10 10 10 2 2 5 and port 5000 and for host it wants a string for port it wants an int which that is fine and then s dot send request we don't have that defined yet time dot sleep uh let's say five seconds okay and then we can say request is equal to um open payload dot read lines oh there's multiple lines here i'm going to do payload.b64 0 and then we can say import base64 and then request is equal to base64.b64 decode request and then before sending it to the server i actually just want to send it to myself so let's say 127.001 to make sure everything looks as expected so python3 exploit.pi nclvnp 5000 so we get a connection get slash this looks normal and i'm guessing what happened before when i did the netcat me hitting enter i did a line break here and it ended that request or something we don't want that and netcat didn't send anything until i did hit enter so it's like checking before the egg situation so that's why i'm resorting to python to do this so we can edit this swap this out to send it here if i refresh this page we only have the three run it it's going to sleep for 5 seconds but i should always win the race condition because ha proxy is no longer going to send the request within the 5 seconds refresh the page boom new note and we get the session notice this x board it's kind of chunked here and the reason why is because the um content length so actually we can just cap this real quick echo dash n let's put this in single quotes wc-c that's 269 and then if we look at the actual request ctrl shift b to on base64 let's see 269 is there a note is five so there's something slightly off um i'm guessing like these spaces are actually more than one character so it's probably backslash our backslash n and it's just showing it as a space but that's probably the issue why it's a bit different because 269 plus the 5 here which would be 274 and there's probably six lines here and it's just counting the lines incorrectly if you really wanted to we could try upping this so let's say 290. let's send it a few times i think that time maybe we hit the um thing so let's see that was the last one let's check these two do any of these have notes delete yep so now we have more so that's exported for 10 10 and if we increase that a little bit more let's say 330 one two three let's see if we got any yeah ah doesn't look like we had any hits we should convert this over to the python script but i was just being lazy if we don't have anything i'll convert that to python and see there we go we have the full exported four i think nope that is my request let's just convert this to base64 control b copy v payload.b64 python3 exploit it's going to wait the five seconds okay that's done refresh this page oh we don't have anything so maybe the content length is too long at this point i'm going to run it one last time and then if it's too long i'm going to shrink that content length down so we're not getting anything ctrl shift b content length let's say stair 330 305 let's try that b payload.b64 wait a few seconds okay i'm not sure what i broke 290 and if this doesn't work i'm probably moving on hopefully i explained it well enough let's see cat payloads b64 basic four dash d 290 okay come on i wonder that x4 and 4 is the last piece there we go i'm not getting the ip but i'm sure if i increase that slightly we'd see but yeah let's just take this cookie and move on so go to storage paste actually see dev chef did not get them all say refresh i am admin and only enough i wonder let's see do i have view let's copy this link or we can just click the link now and even admin can't view um a low priv user's notes that was just a interesting thing i knew admin couldn't like list their notes but i assumed if he knew the id he'd be able to hit it but guess not so we have three different credentials um nagios admin we have like nagios.sync.htb so what i would generally do is uh v etsy hosts and add each of those hosts so we can do nagiosync.htb go over here code.sync.hdb whoops oh that copied a bunch of junk there we go and then the last one would be chef and then i would hit each of these on port 3000 and 5000 to see if i go to a different page none of them actually bring you to a different page so i'm going to ignore that on not wasted time nagios is like zabbix if you know zabbix if you don't know it's just a monitoring application it just runs a script every x minutes or seconds and tells you if a service is up and down it may ping a host and things like that so it's an infrastructure monitoring application code i don't know what code is chef um we just want over shaft and knife it's like a devops tool code maybe like vs code or something like that but i don't know exactly what that is but the idea is you're trying the username and password in each of these so dev node if we do code and try logging into each service um we don't need to log into this one because we're already admin we could potentially want to see the notes of other users since admin can't view the notes but sake of time i'm going to log in here this was root i think was the username and the password and log in again that one was here this dev node so it's password reuse let's clean up our tabs and now that we are in this we can see a few git repos oddly enough it says four repositories but three are listed if i go to explore we have one archived repository so let's go to elasticsearch this one um looks interesting it's elasticsearch which i think is port like 9200 and then cabanas 5601 both those ports weren't listening so i'm kind of ignoring this because i don't see elasticsearch running we have this serverless plugin and looking through this let's see package.json what is it using saying it's running stack logo stack's default port is 4566 so we can't access it if you know from um i think bucket was the other machine that used local stack so far it emulates like aws we have no way to access this so kind of put down the back burner um serverless is like amazon's keyword for lambda or maybe lambda is the keyword for serverless but this is probably some type of lambda thing if we look at example service serverless.yaml we can see it's like a hello world application potentially but you can kind of ignore that we have this key management that is archived so looking at this uh key management ec2 instance check and key rotation and then the final thing is log management and looking through this uh it looks like it is cloud watch again we don't have any way to hit 4566 so i'm going to ignore it we have some access keys though and they're commented out i'm going to look at the history to see if it was ever committed for that so looking at this we can see we do have their aws secrets and default region here and a git commit so this is definitely interesting we have chef events as well as a log name but what i want to do is go to key management and looking at where like a config may be maybe keys.php and this is talking about kms for documentation don't really see anything i'm looking for like a config does config exist no ec2 it's doing a save key location here to save a private key if i do history here we can see it's adding an ec2 key and this is just a ssh key we can view the file copy and paste this so oops save v um i think marcus was the name paste that key sh dash i marcus dot pam marcus at 10 10 10 2 2 5 and unprotected key file let's do chmod 600 and that is wrong was marcus the name of this let's see we began key and it's telling us it's an invalid format which is definitely annoying see vmarcus.pem doesn't want a line break at the end of this huh but the other way if you didn't want to look at individual files you could just look at commits and if you look at the commit for adding ec2 key management you can see it here so there's something weird about this i'm just gonna do raw and i wonder if i can just w get this file uh file not found because we need the cookie i'm just gonna do file save page as and we can do hdb sync and call this i'm just gonna call it marcus i'm not gonna do the ppk v marcus.pem oh it's in smuggle cat marcus okay chmod 600. let's try ssh-i marcus and see if we log in we do so what is different between these two keys um diff marcus and smuggle marcus.pem what cat marcus cat mark smuggle marcus dot pam these look very similar but smuggle oh it probably just have to trim those beginning spaces did not notice i had those when i pasted it in see i could have probably just done like ass colon 4 spaces g like that what percent s one two three four five let's just clear that there we go so now if i sh-i smuggle marcus.pam mark is at 10 10 10 2 2 5. all those are in the world so that works so whenever you see that error about ssh keys be sure to take a look at it in depth but now we are marcus on the sync box going back to the um get t we had elasticsearch lambda kiwi management and log management functions so i'm going to check if elastic is running so i'm just going to do ss lntp to look at listening ports and these 6000s i'm going to guess is going to be like docker the main thing i'm looking for is port 9200 or um 5601 which is elasticsearch and cabana i don't see those so i'm pretty much just going to ignore this search thing the next thing is lambda and we can check if we have like aws tools installed we have aws and aws local i'm going to use aws local because this is a local stack one that's designed to work with it if we just use aws we need to like dash dash endpoint url and also specify a secret key but if we just do aws local we don't have to worry about any of that so aws local and they can do help to get like the man page for it and we can look at all the services we have so this can be the second argument we have tons and tons but one of them is lambda so i'm going to do aws local lambda help and we can look at things i'm going to look for something that's relatively basic that anyone could do like list dash functions so aws local lambda list dash functions and we get a error 400. so i'm going to ignore that if you went back to this aw help or aws help one of them is cloudwatch and there's also i wonder what the different cloud watch and logs is uh aws local cloud watch help amazon cloud watch monitors this delete alarms let's see is there like describe alarms so this looks like it's interacting with cloud watch there's also a logs which still uses cloud watch but it's a little bit different i think yeah so i'm guessing logs is how to like view native logs and then the cloud watch command would be viewing events the difference between like a log and an event would be a log is a password denied an event would be oh this was password denied 50 times it's probably a brute force it's my assumption but we're going to do aws logs and then if we do describe log groups we can see there is a cloudtrail log so we can do that say cloudtrail no that was cloudwatch i don't know exactly but describe log groups and if we kept doing help we can find out there's a describe log streams which is kind of like a folder so when we do this we have to give it a name so log group name i'm going to do cloudtrail so it's going to list all the logs related to cloudtrail and there's only one file which is a stream streams are kind of like files you can see each stream is going to be the date so in 2020 12 22 which is probably when this box was created a good way to look at when a box is created i like doing ls la etsy ssh and then what is it um yeah ssh and then grepping for key so we can see actually may 7 2020 is probably when this box was built so built back in may but this log was created in december the reason why i use this for identifying like when a box was built is because people generally don't update the ssh host keys because when you do you get that nasty ssh banner saying the host key has changed so this file generally gets created on boot and it stays the same so maybe this is when like the um container was made for cloudtrail but we want to look at that log stream so i'm going to instead do describe log streams i'm going to say get log streams and then we gotta specify log stream name and we can just copy this aws logs get log dash stream oh get log events we need the events in that stream and we can see a bunch of things so ingestion time and time stamp this is the time the log was created this is when it got ingested into the platform i'm not sure why there's such a big delta here but we can see rotate secret tag source assume role put scaling policy rotate secret rotate secret if we look at the um get t there is something for key management but this is kms um so that's slightly different than what this is if we do rotate secret oh come on don't do google there we go we can look at functionality around here which is just part of the aws secrets manager if i do aws local help and we search this for secrets is it capital s there should be a secrets manager here i'm not sure why search wasn't working lmnop yeah secrets manager so we can do aws local secrets manager then help and see the functionality in here a bunch of things but the key one is um probably list is there a list yeah list dash secrets and we can see there are jira support sync panel and jenkins login so we want to do a get dash secret is it get secret to get secret value i've always forget this one help it is whoops come on get secret value so get secret value and if you did help again you'd see how to use this we want dash dash secret dash id so we can do secret id and then what was the first one is it jenkins login and we can see username john sync.htb and we have a password so i'm going to cat etsy passwd let's grab for ash and we have users root marcus david and get no user called john right yeah so let's go back to the list secrets the other one was sync panel so let's look at sync panel this user is albert we can look at the other one jira support and this is david and david did exist on the box if i just grep david for etsy pass wd we have it and if we try this password i'm not going to do the backslashes because backslashes are just escaping the double quotes so su-david paste the password in and we are logged in as david doing an lsla on his directory there is this projects folder going into it there's prod deployment and then we have this servers.enc file generally enc stands for encrypted but we can just run the ent command for entropy and it's not found so let's base64 encode it dash w zero so we put it all in one line we can copy this to our host so echo dash n paste this base64 d we can see it's a bunch of gibberish let's put it to dot enc forget what it was called but here i have this entropy command and we can see it's 7.6 bits per byte there's eight bits in a byte so this is high entropy if we just look at standard text like let's look at etsy past wd i'm going to guess it's between like five and six maybe it's four yeah here we go 4.8 so standard text is going to be around four to six bits per byte probably but because this is so close to eight chances are this is definitely encrypted text we could xxd it to see if there's some type of header so xxd servers.enc and i don't recognize anything here i was looking for like some type of algorithm beginning with it but can't make sense of that there was a kms repository which is a key management system i think and it talks about it i think like list keys and things like that we don't have to use this app again we can use aws local and if i do kms help we can see the functions here uh we can encrypt decrypt files things like that but the main thing i want to do right now is list keys so i'm just going to do aw kms list dash keys and we have a lot of keys unlike the um like logs we only had one folder going through each of these manually would be a pain so i'm going to grip this for key id and then i'm going to say awk field separator is a double quote and this would be 1 2 3 i believe so i'll do print three and we get a colon so this is probably one two three and four so it's probably actually 4. so now we just have a list of key ids so i can do 4i and this and then echo i and we get a forgot to do do echo i now we have a clean list of just key ids so from here i can do um aws local then what is it kms is it get key dash dash id i like that so if i look at this that's not it list keys let's see what is it oh describe key right here so instead of get key i'm going to do describe key and we need dash key dash id like that and we output a bunch of information about this like we can see it's usage what type of state it's in it's disabled so this is probably why that like um well no i was gonna say why the key was rotating but that was a different key management system but we probably should look through each of these keys and find out which one is disabled but first let's fix this so kms and it is describe key and this is dash dash key id and once i get this command working i'm going to clean up the syntax and just put it in a bash script for like readability okay so we have this so what i want to do is grep for key state let's see we gotta get rid of this echo because it's just echoing the command so i actually want to run aws local now and we're getting a list of all the key states so we can see disable disabled disabled enabled and the issue we're having right now is we don't know what the key id was anymore so let's go back to our loop before we do this describe key i'm going to say echo dash n and then we can say i semicolon or colon and then end it with semicolon and now we can get a list of every key so let's go and clean this loop up in case you wanted to read it and have trouble with this line break so i'm just gonna do a new thing get keys.sh so this is the for loop put a line break after do echo like this and that's the loop so for every key up here enter the key name then run this aws local command so now we just want to describe these two keys so we can go all the way up here put this key id and look at the purpose of this key we can see encryption and decryption so that looks good let's just for sanity check this second one see if this is also for encryption we can see this is digital signature verification so we don't really care about that we just want this key so we have an encryption decryption key if we do aws local kms help decrypt so let's do decrypt help we can see how to use this decryption so here's all the arguments we definitely want the ciphertext and the key id and then encryption algorithm so let's look at the encryption algorithm a little bit encryption algorithm and there's three possible values symmetric rsa a e s o e p sha1 and sha-256 i'm just gonna put actually let's copy this i don't put on my clipboard but i'm probably going to use my clipboard for other things so let's see there we go the keys so we have that saved okay this is definitely the key right encrypt decrypt so instead of describe key we're going to change this to be decrypt and then we want to do the key id which we have there and then cipher text blob and we can say file and i think it's just servers.enc is what it was and then encryption algorithm and we can say symmetric default and then output is equal to text ciphertextblob unable to load parameter please use file b instead of file okay not exactly sure why maybe it's like file blob but hey it whatever it tells me to do i'm gonna do it so invalid cipher text exception when calling don't know what that is i'm just going to change to a different um algorithm so the next one was r s a e s underscore o a o a e p sha1 and let's try sha-256 and we actually get data back it's a base64-bit a blob but we have data so let's echo dash n uh it looks like a copy of the line break let's leave it this copy up to here echo dash n a 64-d and i don't know exactly what we have here oh wait it output into text right so we did servers let's see output text asking maybe that was a text file let's just try copying this again and we'll do it on our box and we're going to check the entropy so echo dash n the base 64. let's call it unknown like that and then ent unknown 7.2 bits of entropy if we run file against it it says it's gzip data if i had xxd it um i think this is the gzip magic bite all these like there's eight errs in sequence this indicates that it's not random data so uh the chance of having all these years in a row would be low so since file told us it was a gzip let's just rename this so i'm just going to move unknown to unknown.gz and we can say gzip d unknown and now if i do file against unknown it's just a tar archive so we can do tar xvf unknown and we get two files out of that so this was a tar.gz um if we make dur or we already have temp i'm gonna move unknown dot gz actually it's removed um echo so move unknown to temp unknown dot tar dot gz so you could have done this way if you knew it was a tar to begin with and just did taro dash x jvf i think for gzip uh let's see xzvf unknown tar.gz and also extract the files that way so we have servers.sig and servers.yaml and we have admin and then what looks like to be a password so we can again try this password on the box so sq-paste in this password and we are now root on sync so we can cat root.text and we have the key but before we end the video i wanted to show off one super cool technology that went into this box to make it stable um when mr ebro created this box it was originally not friendly to multiple users doing it because that http smuggling piece that's a very big race condition that depends on the next person making an http request and the first revision of this box only had one docker container running in reality we have 16 containers running and we do some ip modular routing to send people to unique containers and the reason why is if you were doing a go buster attack on this box while i was doing an http smuggling then the automated user would never tag on to my smuggling attack because girl buster was always going to be the next http request so we need to come up with a way to help minimize the chances of some other user getting onto your smuggling attack so what we came up with was routing based upon the last octet of an ip address and sending that to a unique container if you watched my last video the uhc september qualifier i went with a kernel module to do this oxdf was looking at iptables simultaneously because we knew it was possible in ip tables but weren't quite showing the syntax and if we didn't do it in time we would have defaulted to the kernel routing because i knew how to do it in the kernel the reason why we didn't want to go with a like other load balancing solution like pound is because that would break the http request smuggling altogether because the pound may behave differently than h a proxy then that goes to g unicorn we didn't want to put another technology on top of h.a proxy so that's why we're going with iptables or kernel module we went with iptables because there's less custom code involved which means there's a less chance of vulnerability at least in our eyes i don't trust the code i write i threw in the uhc box because i wanted to see it work but could have used this iptables method so if i do iptables-l-n i'm actually not going to see the routing because it's on the pre-routing chain so we have to do t-nat to show those chains and whenever you're looking at ip tables you should throw this flag in because someone malicious may put something in this pre-routing thing to um change where things go uh pre there it is so we can see these are the rules if you don't want to remember that you can just do iptables dash save and i actually prefer this output more so we can see here's all the iptables rules we did to make this so this is dash s for source so this is looking at the source ip and then it does some weird like subnet mask thing so iptables does everything inverted and i think this was the big key oxdf found out to make this rule work um in traditional subnetting this would be two five five two five five two five five two forty um and this last octa is 15 240 plus 15 would be 255 which means that subnet mask bit is full which is key for um subnetting but there's going to be a total of 16 ip addresses in this block because 0 is not null it's an actual value number so 0 to 15 is equal to 16. so that's why we have um 0 through 15 here this is just saying if it's tcp this is destination port 5000 so only if it's going to that g unicorn server and then dash jdnat this is routing it to the actual container so this is the first container listening on uh 6000 but it's going to 8080 second container third container fourth container whatever so 10 10 14 0 matches this 10 10 14 1 10 10 14 2 10 10 14 3 10 10 14 15 goes here and then how subnet masks work if we did 10 10 14 16 it goes back down to zero this would be 17 18 19 and then this would be i think 31 would match here and 32 would go back up here so that's kind of how the iptables modulo routing thing works so hope that made sense take care guys and i'll see you all next week oh if it doesn't make sense view oxds blog i'm sure he does a much better explanation of it but yep take care and i'll see you all next week